# Justification

GNU/Linux philosophy have been developed under the Open culture, this characteristic aims to provide users the option to learn, share, fix or talk about solutions to any problem or issue with a dependency, an specific task and so on. This approach creates a continue workflow of options for users to solve their problems with their systems or their particular tasks. In principle, that workflow provide a huge amount of solutions, for a great diversity of problems; but that approach have created some particularities had made of GNU/Linux environment a difficult one for new users and experimented users, [if you check sites like SourceForge you will quickly realize that - Find a better ref].

It is well known on GNU/Linux community that you can install at least two different packages for anything you need to do, which is a good example of the choosing paradox [Get some philologist here](https://en.wikipedia.org/wiki/The_Paradox_of_Choice), in which you don't know what to choose due to the amount of options each with pros and cons inherent to their context (Find a ref about this), this is the reason it is so common on GNU/Linux community to write large wikis with a set of different solutions. Arch Linux wiki or Ubuntu Forum are two example of those centric sites to look for solutions, information or options. In short, they are well documented and organized, indeed it is so common for new users to have the necessity of keep looking for hours a solution, a system could provide with a short sente, a command or a package, what is the most common solutions users are looking for. In the other hand, when experimented users have a problem those problems generally are related to package's state, a miss configurations of two or more tools or simple the necessity to install an specific package, so the cycle starts again for them, having the necessity to look for solutions reading for hours.

[comment]: <> (Expand here about Users needs and problems)

The proposal is to use a Virtual assistant (VA) directly installed on each user machine getting the context from user's OS giving context to a cost-efficient pre-trained LLM based on Llama v2 to improve accuracy of given solutions, directly having the systems context reading OS characteristic from man and help command outputs, differing with options like ChatGPT, Gemini or similar GTPs models that need to have context to be provided as a prompt that depends on user previous knowledge of the problem